#!/usr/bin/env python
# coding: utf-8

# **Описание проекта "Исследование поведения клиентов компании «Пока все ещё тут»"**
# 
# Данный проект направлен на исследование и анализ данных интернет-магазина товаров для дома «Пока все ещё тут» 

# **Ссылка на презентацию - https://drive.google.com/file/d/1rWq7R4TucvR8ctfh7l0LJzssLW1lLRCe/view?usp=sharing**

# **Цели исследования**

# - Оценить ключевые показатели работы магазина за выбранный период
# - Провести анализ ассортимента товаров и выделить основные товарные категории
# - Сегментировать покупателей на основе их поведения и покупательской активности
# - Провести сравнение сегментов по ключевым метрикам
# - Проверить статистические гипотезы о различиях между сегментами
# - Сформировать рекомендации по персонализации, маркетингу и работе с клиентами

# **Шаг 1. Предобработка данных**

# Импортируем необходимые библиотеки

# In[1]:


import pandas as pd
import datetime as dt
import numpy as np
import matplotlib.pyplot as plt
from pandas.plotting import register_matplotlib_converters
import scipy.stats as st
import math 
import seaborn as sns
import re
from scipy.stats import mannwhitneyu
from itertools import combinations
import matplotlib.dates as mdates 
from statsmodels.stats.multitest import multipletests


# Изучим основную информацию о данных

# In[2]:


data = pd.read_csv('/datasets/ecom_dataset_upd.csv')
data


# In[3]:


data.info()


# Преобразуем формат даты, предварительно избавимся от ненужных двух нулей в конце 

# In[4]:


data['date'] = data['date'].astype(str).str[:8]
data['date']


# In[5]:


data['date'] = pd.to_datetime(data['date']).dt.date
data


# Проверим данные на пропуски

# In[6]:


data.isna().sum()


# Пропуски отсутствуют

# Проверим данные на явные дубликаты

# In[7]:


print(f"Количество явных дубликатов: {data.duplicated().sum()}")


# Удалим явные дубликаты

# In[8]:


data.drop_duplicates()


# Проверим данные на неявные дубликаты

# In[9]:


duplicate_orders = data.groupby(['order_id', 'customer_id', 'date', 'product']).size()
duplicate_orders = duplicate_orders[duplicate_orders > 1]

display(duplicate_orders)


# Удалим неявные дубликаты

# In[10]:


order_date_counts = data.groupby('order_id')['date'].nunique() # Группируем по order_id и смотрим уникальное количество дат
orders_with_multiple_dates = order_date_counts[order_date_counts > 1].index


# In[11]:


sample_orders = data[data['order_id'].isin(orders_with_multiple_dates)]
print(sample_orders.sort_values(by=['order_id', 'date']))


# In[12]:


data_sorted = data.sort_values(by='date') # Сортируем по дате (чтобы поздняя дата шла последней)
data_cleaned = data_sorted.drop_duplicates(subset=['order_id', 'product'], keep='last') # Удаляем дубликаты, оставляя последнюю запись


# In[13]:


data_cleaned


# Добавим столбец с выручкой

# In[14]:


data_cleaned['revenue'] = data_cleaned['quantity'] * data_cleaned['price']
data_cleaned


# In[15]:


multi_customer_orders = data_cleaned.groupby('order_id')['customer_id'].nunique() #определяем заказы, у которых больше одного покупателя
bad_orders = multi_customer_orders[multi_customer_orders > 1].index
data_cleaned = data_cleaned[~data_cleaned['order_id'].isin(bad_orders)].copy() #удаляем строки, относящиеся к таким заказам


# In[16]:


data_cleaned


# Проверим данные на аномалии

# In[17]:


plt.figure(figsize=(15, 10)) 
plt.boxplot([data_cleaned['price'], data_cleaned['quantity'], data_cleaned['revenue']], labels=['price', 'quantity', 'revenue'])
plt.title("Боксплоты для цены, количества и выручки")
plt.ylabel("Значение")
plt.show()


# Заметен один большой выброс в столце выручки, из-за которого неудобно смотреть на графики, поэтому удалим его и снова посмотрим на графики

# Отфильтруем выбросы с помощью межквартильного размаха

# In[18]:


percentile_99 = data_cleaned['revenue'].quantile(0.999) # Вычисляем 99,9-й перцентиль для столбца 'revenue'
data_cleaned = data_cleaned[data_cleaned['revenue'] <= percentile_99]# Фильтруем данные, оставляя только те строки, где выручка не превышает 95-й перцентиль


# In[19]:


data_cleaned


# In[20]:


orders_per_customer = data_cleaned.groupby('customer_id')['order_id'].nunique().reset_index()
orders_per_customer.columns = ['customer_id', 'order_count']


# In[21]:


plt.figure(figsize=(15, 10)) 
plt.boxplot([orders_per_customer['order_count']], 
             labels=['order_count'])
plt.title("Боксплоты для цены, количества и выручки")
plt.ylabel("Значение")
plt.show()


# Удалим значения выше 99 перцентиля

# In[22]:


q99_orders = orders_per_customer['order_count'].quantile(0.99)
valid_customers = orders_per_customer[orders_per_customer['order_count'] <= q99_orders]['customer_id']
data_cleaned = data_cleaned[data_cleaned['customer_id'].isin(valid_customers)]


# In[23]:


data_cleaned


# In[24]:


plt.figure(figsize=(15, 10)) 
plt.boxplot([data_cleaned['price'], data_cleaned['quantity'], data_cleaned['revenue']], 
             labels=['price', 'quantity', 'revenue'])
plt.title("Боксплоты для цены, количества и выручки")
plt.ylabel("Значение")
plt.show()


# Остальные значения выглядят вполне правдоподобно, поэтому их оставим

# **Выводы**
# 
# На данном этапе были выполнены следующие шаги:
# 
# - импортированы необходимые библиотеки
# - данные были проверены на наличие пропусков - пропуски отсутствуют
# - данные были проверены на явные дубликаты - 966 явных дубликатов было удалено
# - данные были проверены на неявные дубликаты - 2133 неявных дубликата было удалено
# - был добавлен столбец с выручкой
# - данные были проверены на аномалии  - удалена одна строка с аномальным значением в столбце с выручкой

# **Шаг 2. Исследовательский анализ данных**

# Проведем сегментацию товаров по категориям, для этого выведем список уникальных наименований товаров из столбца product

# In[25]:


data_cleaned['product'].unique().tolist()


# Сделаем словарь с ключевыми словами для каждой категории

# In[26]:


categories = {
    "кухня": [
        "нож", "рыбочистка", "кисточка", "картофелемялка", "блендер", "сковорода", "сито", "ложка", "миксер", 
        "салатник", "тарелка", "стакан", "кружка", "чашка", "пиала", "салатник", "графин", "бокал", "стопка", "тарелка десертная",
        "кувшин", "скатерть", "термостакан", "мантоварка", "кондитерский", "термос", "толкушка", "чайник", "салфетка",
        "кофейник", "форма для выпечки", "лопатка", "блюдо", "маслёнка", "солонка", "пищевой", "кухонный", "дуршлаг",
        "картофелемялка", "фужеров", "лопатка", "чайный", "просеиватель", "эмалированный", "банка", "котел",
        "сотейник", "вилка", "сковороды", "орехоколка", "противень", "масленка", "овощеварка", "терка", "хлебница", "кухонных"
    ],
    "ванная и уборка": [
        "средство для мытья", "средство", "освежитель", "порошок", "гель", "моющее средство", "губка",
        "мыло", "зубная", "стирки", "стирка", "швабра", "стирка", "порошок", "гель для стирки", "ополаскиватель", "кондиционер для белья", 
        "щетка", "совок", "ведро", "тряпка", "салфетка", "перчатки", "губка", "средство для мытья", "очиститель", "дезинфекция", "уборка", "чистка", 
        "пятновыводитель", "веники", "мыльница", "дозатор", "коврик для ванной", "занавеска", "держатель", "зубная щетка", "зубная паста", "шампунь", 
        "гель для душа", "полотенце", "мочалка", "крючок", "корзина для белья", "контейнер", "полка для ванной", "щетка для унитаза", "освежитель", 
        "чистящее средство", "душ", "мыло", "органайзер", "дезодорант", "стакан для щеток", "щипчики", "бритва", "ёршик", "ершик",
        "ополаскиватель", "вантуз", "ерш", "ёрш", "унитаза", "ванн", "ванна", "веник", "пятен", "сметка"
    ],
    "ремонт и инструменты": [
          "отвертка", "молоток", "дрель", "шуруповерт", "гвоздь", "саморез", "дюбель","изолента", "герметик", "шуруп", "ключ", 
          "уровень", "скотч", "пила", "инструмент","паяльник", "ремонт", "шпатель", "строительный", "перфоратор", "сверло","стремянка",
            "досок", "доска", "отвертка", "молоток", "дрель", "шуруповерт", "гвоздь", "саморез", "дюбель", "изолента", "герметик", "шуруп", 
            "ключ", "уровень", "скотч", "пила", "инструмент","паяльник", "ремонт", "шпатель", "строительный", "перфоратор", "набор инструментов", 
           "шлифовка", "рулетка", "болт", "бетон", "тележка", "петля", "лестница", "крепеж", "пружина", "сверел", "бензин", "сварка", "шнур",
        "линейка", "фал", "паста для полировки"
        
    ],
    "товары для дома": [
        "сушилка для белья", "полотенце", "щетка", "картон", "плед", "подушка", "покрывало", "мыло", "запах", "покрывало", "гладильная", "муляж",
        "коврик", "гладильная", "корзина", "комод", "корзина", "шкаф", "полка", "полки", "тумба", "стеллаж", "система хранения", "ящик", 
        "гардероб", "кровать", "контейнер", "штора", "вешалка", "весы", "простынь", "декоративный", "подставка под свечу", 
    "панно", "статуэтка", "вышивка", "сумка", "чехол", "наматрасник", "декоративная", "фоторамка", "этажерка", "ковер", "ковёр", "таз пластмассовый",
        "простыня", "плечики", "штор", "подставка для обуви", "вешалок", "гладильной", "подрукавник", "вешалки", "ролик", "ролика",
        "искусственная композиция из цветов пластиковая"
    ],
    "растения и сад": ["растение", "зональная", "цветущая", "цветок", "пеларгония", "рассада", "эвкалипт", "суккулент", "лутесценс",
                       "аспарагус",  "кашпо", "горшок", "растение", "грунт", "удобрение", "рассада", "саженец", "лейка", "секатор", 
                       "лопата", "грабли", "шланг", "сад", "садовый", "цветочный", "цветок", "полив", "опрыскиватель", "парник", "садовод", 
                       "сажать", "красная", "розовоцветная", "оранжевая", "черенок", "спатифиллум", "фиолетовая", "космея", "зев",
                       "пуансеттия", "розмарин", "ель", "дерево", "королевский", "h", "d", "пыль", "роза", "пламя", "томата", "петрушка",
                       "укроп", "базилик", "кориандр", "хризантема", "цинния", "котовник", "незабудка", "пиретрум", "физостегия",
                       "бархатцы", "ранункулус", "огурец", "морковь", "клубника", "настурция", "петуния", "клен", "фуксия", "гвоздика"
                       
    ],
    "прочее": []
}


# In[27]:


def categorize_item(item_name, categories_dict):
    item_name = item_name.lower() # приводим название товара к нижнему регистру
    for category, keywords in categories_dict.items():
        if any(keyword in item_name for keyword in keywords):
            return category
    return "прочее"


# In[28]:


data_cleaned['category'] = data_cleaned['product'].apply(categorize_item, categories_dict=categories)


# Посмотрим на распределеие количества товаров по категориям

# In[29]:


category_counts = data_cleaned["category"].value_counts()

plt.figure(figsize=(10, 6))
category_counts.plot(kind="bar", color="skyblue", edgecolor="black")
plt.title("Распределение количества товаров по категориям")
plt.xlabel("Категория")
plt.ylabel("Количество товаров")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()


# In[30]:


category_counts 


# Самая большая категория - растения и сад (2673), самая маленькая - прочее (238)

# Построим график с динамикой выручки по месяцам

# In[31]:


data_cleaned['date'] = pd.to_datetime(data_cleaned['date'], errors='coerce')


# In[32]:


data_cleaned['month'] = data_cleaned['date'].dt.to_period('M').astype(str)
monthly_revenue = data_cleaned.groupby('month')['revenue'].sum().sort_index()

# Построение графика
plt.figure(figsize=(12, 6))
monthly_revenue.plot(marker='o', linestyle='-', color='royalblue')
plt.title('Динамика выручки по месяцам')
plt.xlabel('Месяц')
plt.ylabel('Выручка')
plt.grid(True, linestyle='--', alpha=0.6)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()


# - По графику можно заметить тенденцию к снижению выручки к концу периода анализа. 
# - Максимальный показатель был в начале периода - октябрь 2018. 
# - Минимальный показатель - в ноябре 2019. 
# - Заметные подъемы происходят в декаре 2018 и 2019 года - это может быть связано с покупательской активностью перед новогодними праздниками. 
# - Также заметен рост выручки в апреле - это может быть связано с тем, что в ассортименте товаров преобладают товары категории "растения и сад", а в апреле как раз возобновляется сезон работы в садах и огородах

# In[33]:


monthly_orders = data_cleaned.groupby(['month', 'order_id'])['revenue'].sum().reset_index()

# Теперь считаем средний чек: средняя сумма заказа по каждому месяцу
average_check = monthly_orders.groupby('month')['revenue'].mean()

# Построение графика
plt.figure(figsize=(12, 6))
average_check.plot(marker='s', linestyle='-', color='royalblue')
plt.title('Динамика среднего чека по месяцам')
plt.xlabel('Месяц')
plt.ylabel('Средний чек')
plt.grid(True, linestyle='--', alpha=0.6)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()


# - В динамике среднего чека также заметна тенденция к снижению показателя к концу периода анализа
# - Максимальный показатель - июнь 2019
# - Минимальный показатель - ноябрь 2019
# - Можно заметить, что максимальный средний чек был в июне, но выручка в этот месяц была не максимальна. Это может быть связано с  тем, что товаров покупалось не так много, однако они были дорогими

# In[34]:


# Группируем: считаем суммарную выручку и количество уникальных покупателей по месяцам
monthly_revenue = data_cleaned.groupby('month').apply(
    lambda x: pd.Series({
        'total_revenue': (x['price'] * x['quantity']).sum(),
        'unique_customers': x['customer_id'].nunique()
    })
).reset_index()

# Добавляем колонку средней выручки на покупателя
monthly_revenue['avg_revenue_per_customer'] = monthly_revenue['total_revenue'] / monthly_revenue['unique_customers']

# Строим график
plt.figure(figsize=(12,6))
plt.plot(monthly_revenue['month'], monthly_revenue['avg_revenue_per_customer'], marker='o', color='royalblue')
plt.title('Динамика средней выручки с покупателя по месяцам')
plt.xlabel('Месяц')
plt.ylabel('Средняя выручка с покупателя, ₽')
plt.xticks(rotation=45)
plt.grid(True)
plt.tight_layout()
plt.show()


# График средней выручки с покупателя выглядит подобным графику среднего чека.

# Посмотрим на эти же показатели в разрезе категорий

# In[35]:


# Выручка по месяцам и категориям
category_monthly_revenue = data_cleaned.groupby(['month', 'category'])['revenue'].sum().reset_index()

# Уникальные заказы и покупатели
monthly_orders_customers = data_cleaned.groupby('month').agg({
    'order_id': pd.Series.nunique,
    'customer_id': pd.Series.nunique
}).reset_index().rename(columns={
    'order_id': 'unique_orders',
    'customer_id': 'unique_customers'
})

sns.set(style="whitegrid")
plt.figure(figsize=(14, 6))

sns.lineplot(
    data=category_monthly_revenue,
    x='month', y='revenue', hue='category', marker='o'
)

plt.title('Динамика выручки по категориям')
plt.xlabel('Месяц')
plt.ylabel('Выручка')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()


# In[36]:


data_cleaned.groupby('category')['revenue'].sum().reset_index().sort_values(by='revenue', ascending=False)


# Выводы по графикам:
# 
# - Самую большую выручку приносят товары категории ремонт и инструменты, т.к. товары в жтой категории в целом имеют высокие цены, больше всего эта категория приносит выручки в декабре 2018, это может быть связано с желанием обновить ремонт перед праздниками у покупателей и с приобретением подарков 
# - К январю происходит падение выручки у многих категорий - это может быть связано с большим количеством выходных и снижением покупательской активности
# - Выручка у категории растения и сад заметно растет в апреле и падают к августу - это связано с сезоном активности в садах и огородах
# - Товары из категории товаров для дома приносят больше всего выручки летом -  это может быть связано с сезоном отпусков и обновлением интерьера, обсустройством загородных домов и дач, большим количеством переездов
# - Товары из категории кухня достигают пика летом и в сентябре - летом это связано с налчием свободного времени у людей и частой готовкой, в сентябре же проходит сезон заготовок
# - У товаров категории ванная и уборка показатели выручки довольно однородны и определенную тенденцию отметить сложно, однако можно увидеть заметное снижение показателей в мае - это может быть связано с тем что люди готовятся к дачному сезону и отмечают праздники, поэтому актуальность товаров данной категории временно падает
# 

# **Выводы**
# 
# На данном этапе были выполнены следующие шаги:
#  - Была проведена сегментация товаров на следующие категории:
#    - растения и сад (2673)
#    - товары для дома (902)
#    - ремонт и инструменты (575)
#    - ванная и уборка (451)
#    - кухня (432)
#    - прочее (238)
#  - Были проведены сравнения по основным показателям (динамика выручки, среднего чека и средней выручки на одного пользователя) между всеми категориями

# **Шаг 3. Основные вопросы исследования**

# Проведем сегментацию покупателей

# In[37]:


# Рассчитаем Recency 
max_date = data_cleaned['date'].max() # Вычисляем дату последней покупки
recency_df = data_cleaned.groupby('customer_id')['date'].max().reset_index()
recency_df['recency'] = (max_date - recency_df['date']).dt.days
recency_df = recency_df[['customer_id', 'recency']]

#Рассчитаем Frequency 
frequency_df = data_cleaned.groupby('customer_id')['order_id'].nunique().reset_index()
frequency_df.columns = ['customer_id', 'frequency']

# Рассчитаем Monetary 
# Добавляем колонку с общей суммой покупки
monetary_df = data_cleaned.groupby('customer_id')['revenue'].sum().reset_index()
monetary_df.columns = ['customer_id', 'monetary']


# Чтобы установить пороговые значения для сегментов, посмотрим на описательныю статистику каждого показателя с помощью метода describe

# In[38]:


recency_df['recency'].describe()


# In[39]:


frequency_df['frequency'].describe()


# In[40]:


monetary_df['monetary']


# In[41]:


rfm_df = data_cleaned.groupby('customer_id').agg({
    'date': lambda x: (data_cleaned['date'].max() - x.max()).days,
    'order_id': 'nunique',
    'price': 'sum'
}).reset_index()

rfm_df.columns = ['customer_id', 'recency', 'frequency', 'monetary']

rfm_df['recency_score'] = pd.cut(rfm_df['recency'],
                                bins=[ -1, 50, 100, rfm_df['recency'].max()],
                                labels=[3, 2, 1])

rfm_df['frequency_score'] = pd.cut(rfm_df['frequency'],
                                  bins=[0, 1, 2,  rfm_df['frequency'].max()],
                                  labels=[1, 2, 3])

rfm_df['monetary_score'] = pd.cut(rfm_df['monetary'],
                                 bins=[ 9, 700, 1800, rfm_df['monetary'].max()],
                                 labels=[1, 2, 3])

rfm_df['rfm_score'] = rfm_df['recency_score'].astype(str) +                       rfm_df['frequency_score'].astype(str) +                       rfm_df['monetary_score'].astype(str)

print(rfm_df.head())


# In[42]:


rfm_df['rfm_score'] = rfm_df['rfm_score'].astype(int)


# In[43]:


def rfm_segment(row):
    if row['rfm_score'] == 111:
        return 'Неактивные клиенты'
    elif row['rfm_score'] >= 222 and row['rfm_score'] <= 323:
        return 'Лучшие клиенты'
    elif row['rfm_score'] < 222 and row['rfm_score'] > 111:
        return 'Частые клиенты'
    else:
        return 'Other'

    
    print(rfm_df.head())

rfm_df['segment'] = rfm_df.apply(rfm_segment, axis=1)


# In[44]:


rfm_df['segment'].value_counts()


# Образовалось три сегмента - частые клиенты, неактивные клиенты и лучшие клиенты

# In[45]:


data_cleaned = data_cleaned.merge(rfm_df[['customer_id', 'segment']], on='customer_id', how='left')
data_cleaned 


# Сделаем распределение товаров по категориям  каждом сегменте покупателей

# In[46]:


# Распределение категорий товаров в сегментах (в процентах), по количеству купленного товара
category_distribution_pct = (
    data_cleaned
    .groupby(['segment', 'category'])['quantity']
    .sum()
    .groupby(level=0)
    .apply(lambda x: (x / x.sum()) * 100)
    .unstack(fill_value=0)
)

# Построение stacked bar chart с процентами
category_distribution_pct.plot(kind='bar', stacked=True, figsize=(12, 6), colormap='tab20')

plt.title('Распределение категорий товаров по сегментам покупателей (в процентах, по количеству)')
plt.xlabel('Сегмент')
plt.ylabel('Доля категории (%)')
plt.ylim(0, 100)
plt.legend(title='Категория', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.show()


# - Во всех трех сегментах самой популярной категорией является категория растения и сад
# - Наименее популярная категория в сегменте частых клиентов - товары для кухни
# - Наименее популярная категория в сегменте лучших клиентов (попмимо категории прочее)- также кухня
# - Наименее популярная категория в сегменте неактивных клиентов - ремонт и инструменты

# In[47]:


segment_category_revenue = data_cleaned.groupby(['segment', 'category'])['revenue'].sum().unstack(fill_value=0)

# Сортировка сегментов по общей выручке
segment_category_revenue = segment_category_revenue.loc[segment_category_revenue.sum(axis=1).sort_values(ascending=False).index]

segment_category_revenue.plot(kind='bar', stacked=True, figsize=(12, 6), colormap='tab20')
plt.title('Распределение выручки по категориям товаров в сегментах покупателей')
plt.xlabel('Сегмент покупателей')
plt.ylabel('Выручка')
plt.legend(title='Категория', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()


# - Больше всего выручки в сегменте частых клиентов приносит категория ремонт и инструменты
# - Больше всего выручки в сегменте лучших клиентов приносит категория ремонт и инструменты
# - Больше всего выручки в сегменте неактивных клиентов приносит категория товары для дома

# Сравним основные показатели между сегментами по каждой категории товаров

# In[48]:



avg_check_df = (
    data_cleaned
    .groupby(['segment', 'category', 'month', 'order_id'])['revenue']
    .sum()
    .groupby(['segment', 'category', 'month'])
    .mean()
    .reset_index(name='avg_check')
)


revenue_df = (
    data_cleaned
    .groupby(['segment', 'category', 'month'])['revenue']
    .sum()
    .reset_index()
)


# In[49]:


# Установка границ для оси X
start_date = '2018-10'
end_date = '2020-01'

# Преобразуем к datetime, если ещё не преобразовано
revenue_df['month'] = pd.to_datetime(revenue_df['month'])

segments = data_cleaned['segment'].unique()

for segment in segments:
    plt.figure(figsize=(14, 6))
    
    sns.lineplot(
        data=revenue_df[revenue_df['segment'] == segment],
        x='month', y='revenue', hue='category',
        marker='o'
    )
    
    plt.title(f'Динамика выручки по категориям — сегмент: {segment}')
    plt.ylabel('Выручка')
    plt.xlabel('Месяц')
    plt.legend(title='Категория')
    plt.xlim(pd.to_datetime(start_date), pd.to_datetime(end_date))
    plt.xticks(rotation=45)
    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
    plt.grid(axis='y', linestyle='--', alpha=0.5)
    plt.tight_layout()
    plt.show() 


# Выводы по графикам:
# 
# - Частые клиенты
#  - В ноябре 2018 больше всего выручки принесли товары категории ремонт и инструменты
#  - Резкий подъем выручки по категориям ремонт и инструменты, растения и сад происходит с апреля по июнь
#  - Заметен резкий подъем выручки у категории товаров ванная и уборка в феврале 2019 года
#  - По среднему чеку происходит резкий скачок в категории кухня в июне 2019 года, также заметный рост у категории растения и сад
# 
# - Неактивные клиенты
#  - Выручка у неактивных клиентов довольно низкая и редко поднимается выше значения в 20000
#  - Ярко выраженный рост выручки происходит в категории товары для дома в июне 2019 и в ноябре 2018
#  - Ярко выраженный рост среднего чека в категории ремонт и инструменты в марте 2019
#  
# - Лучшие клиенты
#  - Заметно несколько скачков по выручке в категории товаров ремонт и инструменты - декабрь 2018, февраль и март 2019, декабрь 2019
#  - Заметен общий рост вырчки по всем категориям в конце анализируемого периода (с ноября 2019)
#  - Отмечается сильный рост среднего чека в категории ванная и уборка в ноябре 2018

# **Шаг 4. Проверка гипотез**

# Так как в данных присутствуют выбросы, гипотезы будут проверяться при помощи теста Манна-Уитни

# - Нулевая гипотеза: статистически значимых различий в среднем количестве заказов между сегментами нет.
# - Альтернативная гипотеза: статистически значимые различия в среднем количестве заказов между сегментами есть

# - Нулевая гипотеза: статистически значимых различий в среднем чеке между группами нет.
# - Альтернативная гипотеза: статистически значимые различия в среднем чеке между группами есть.

# In[50]:


orders_per_customer = (
    data_cleaned.groupby(['customer_id', 'segment'])['order_id']
    .nunique()
    .reset_index(name='order_count')
)
rfm_df['average_order_value'] = rfm_df['monetary'] / rfm_df['frequency']

segments = orders_per_customer['segment'].unique()


# In[51]:


#Тест по количеству заказов
results = []
p_values = []

for seg1, seg2 in combinations(segments, 2):
    group1 = orders_per_customer[orders_per_customer['segment'] == seg1]['order_count']
    group2 = orders_per_customer[orders_per_customer['segment'] == seg2]['order_count']
    
    stat, p = mannwhitneyu(group1, group2, alternative='two-sided')
    p_values.append(p)
    results.append({'Сегмент 1': seg1, 'Сегмент 2': seg2})


_, p_adj, _, _ = multipletests(p_values, method='fdr_bh') # Поправка методом Бонферрони

for i, p in enumerate(p_adj):
    results[i]['p-value'] = p

results_df = pd.DataFrame(results)


# In[52]:


#Тест по среднему чеку
results2 = []
p_values2 = []

for seg1, seg2 in combinations(segments, 2):
    group1 = rfm_df[rfm_df['segment'] == seg1]['average_order_value']
    group2 = rfm_df[rfm_df['segment'] == seg2]['average_order_value']

    stat, p = mannwhitneyu(group1, group2, alternative='two-sided')
    p_values2.append(p)
    results2.append({'Сегмент 1': seg1, 'Сегмент 2': seg2})


_, p_adj2, _, _ = multipletests(p_values2, method='fdr_bh') # Поправка методом Бонферрони


for i, p in enumerate(p_adj2):
    results2[i]['p-value'] = p

results2_df = pd.DataFrame(results2)

print('Результаты по количеству заказов:\n', results_df)


# Во всех трех случаях p-value меньше 0.5, значит статистически значимая разница между средним количеством заказов среди сегментов есть. Следовательно, сегментация была проведена правильно

# In[53]:


print('\nРезультаты по среднему чеку:\n', results2_df)


# Во всех трех случаях p-value меньше 0.5, значит статистически значимая разница между средним чеком среди сегментов есть. Следовательно, сегментация была проведена правильно

# **Общие выводы**
# 
# - На этапе предобработки были выполнены следующие шаги:
#   - импортированы необходимые библиотеки
#   - данные были проверены на наличие пропусков - пропуски отсутствуют
#   - данные были проверены на явные дубликаты - 966 явных дубликатов было удалено
#   - был добавлен столбец с выручкой
#   - данные были проверены на аномалии  - удалена одна строка с аномальным значением в столбце с выручкой
#   
# 
# - На этапе исследовательского анализа были выполнены следующие шаги:
#  - Была проведена сегментация товаров на следующие категории:
#    - растения и сад (2673)
#    - товары для дома (902)
#    - ремонт и инструменты (575)
#    - ванная и уборка (451)
#    - кухня (432)
#    - прочее (238)
#  - Были проведены сравнения по основным показателям (динамика выручки, среднего чека и средней выручки на одного пользователя) между всеми категориями
#  
# 
# - На этапе основных вопросов и исследований были выполнены следующие шаги:
#  - Проведена сегментация покупателей с помощью метода RFM-анализа, были выделены три сегмента:
#    - Частые клиенты (839 покупателей)
#    - Неактивные клиенты (928 покупателей)
#    - Лучшие клиенты (650 покукупателя)
#  - Выявлены следующие закономерности:
#    - Больше всего выручки в сегменте частых клиентов приносит категория ремонт и инструменты
#    - Больше всего выручки в сегменте лучших клиентов приносит категория ремонт и инструменты
#    - Больше всего выручки в сегменте неактивных клиентов приносит категория товары для дома
#    
# 
# - На этапе проверки гипотез были проверены следующие гипотезы:
#    
#    - Нулевая гипотеза: статистически значимых различий в среднем количестве заказов между сегментами нет.
#    - Альтернативная гипотеза: статистически значимые различия в среднем количестве заказов между сегментами есть.
#  - Вывод: во всех трех случаях p-value меньше 0.5, значит статистически значимая разница между средним количеством заказов среди сегментов есть. Следовательно, сегментация была проведена правильно
#  
#    - Нулевая гипотеза: статистически значимых различий в среднем чеке между группами нет.
#    - Альтернативная гипотеза: статистически значимые различия в среднем чеке между группами есть.
#  - Вывод: во всех трех случаях p-value меньше 0.5, значит статистически значимая разница между средним чеком среди сегментов есть. Следовательно, сегментация была проведена правильно

# **Портрет клиентов по сегментам и рекомендации по персонализации и маркетингу:**
# 
# **Частые клиенты**
# - Поведение:
#   - Декабрь 2018: пик выручки по категории ремонт и инструменты
#   - Апрель–июнь: рост выручки по категориям ремонт и инструменты, растения и сад
#   - Февраль 2019: всплеск по ванной и уборке
#   - Июнь 2019: скачок среднего чека и рост по категории сад
# 
# Рекомендации:
# - Сезонные предложения:
# 
#   - Весной — продвигать садовые и ремонтные товары.
#   - Февраль — кампании по уборке и обновлению интерьера (возможно, связано с подготовкой к весне).
#   - Кросс-промо: покупающим товары для сада — предлагать инструменты со скидкой.
#   - Персонализированные рассылки с акцентом на «обновление дома» и дачные работы.
#   - В июне — предложить премиальные товары (раз чек растёт)
#   
# **Неактивные клиенты**
# - Поведение:
#   - Низкая активность в целом.
# 
# - Пики выручки:
# 
#   - Июнь 2019 — товары для дома
#   - Ноябрь 2018 — тоже дом
#   - Март 2019 — скачок среднего чека по категории ремонт и инструменты
# 
# Рекомендации:
#  - Реактивационные кампании:
#    - Акции на «товары для дома» в июне (судя по прошлому поведению, этот месяц работает).
#    - Предложить персональную скидку на ремонтные товары в марте.
# 
# **Лучшие клиенты**
#  - Поведение:
#    - Много всплесков по категории ремонт и инструменты (декабрь, февраль, март, декабрь снова).
#    - Рост выручки по всем категориям с ноября 2019.
#    - Ноябрь 2018 — всплеск среднего чека по ванной и уборке.
# 
# - Рекомендации:
#   - Эти клиенты готовы тратить и делают это регулярно.
# 
# - Лояльность:
#   - Ввести VIP-программу: ранний доступ к новым коллекциям, персональные менеджеры.
#   - Бонусы на конец года — особенно в декабре.
#   - Пакетные предложения: в ремонте — скидки на наборы инструментов и аксессуаров.
#   - Продвигать осенне-зимние кампании (особенно с ноября).
#   - Подчеркнуть удобство и премиальность: подарочные упаковки, расширенная гарантия и т.п.
# 
# 
